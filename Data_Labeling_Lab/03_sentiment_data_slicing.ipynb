{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✂️ Snorkel Intro Tutorial: _Data Slicing_\n",
    "\n",
    "In real-world applications, some model outcomes are often more important than others — e.g. vulnerable cyclist detections in an autonomous driving task, or, in our running **spam** application, potentially malicious link redirects to external websites.\n",
    "\n",
    "Traditional machine learning systems optimize for overall quality, which may be too coarse-grained.\n",
    "Models that achieve high overall performance might produce unacceptable failure rates on critical slices of the data — data subsets that might correspond to vulnerable cyclist detection in an autonomous driving task, or in our running spam detection application, external links to potentially malicious websites.\n",
    "\n",
    "In this tutorial, we:\n",
    "1. **Introduce _Slicing Functions (SFs)_** as a programming interface\n",
    "1. **Monitor** application-critical data subsets\n",
    "2. **Improve model performance** on slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Labeled Data and Define Slicing Functions (SFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initial Setup ---\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn # Ensure nn is imported\n",
    "import utils # Your utility functions file\n",
    "import logging\n",
    "import tensorflow as tf # For reproducibility seed\n",
    "import scipy.sparse # For type checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "tf.random.set_seed(SEED) # Set TF seed as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure logging and display\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING) # Reduce verbose Snorkel logging\n",
    "pd.set_option(\"display.max_colwidth\", 0) # Display full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning full dataset text...\n",
      "\n",
      "Using a SUBSET for training/evaluation:\n",
      "  Training examples: 10000\n",
      "  Test examples: 2000\n",
      "\n",
      "Training Subset Head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>844098</th>\n",
       "      <td>saaaaad day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268963</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118710</th>\n",
       "      <td>lol hilarious  waitis it george bush the one who gets with a shoe or  sth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340147</th>\n",
       "      <td>are already more than three hours and i have not lunch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393637</th>\n",
       "      <td>i miss my bff keith ambers i wish i can visit him soon in australia im not contented with these ims and phone calls come bck keith</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                        text  \\\n",
       "844098   saaaaad day                                                                                                                           \n",
       "1268963                                                                                                                                        \n",
       "1118710     lol hilarious  waitis it george bush the one who gets with a shoe or  sth                                                          \n",
       "340147   are already more than three hours and i have not lunch                                                                                \n",
       "393637   i miss my bff keith ambers i wish i can visit him soon in australia im not contented with these ims and phone calls come bck keith    \n",
       "\n",
       "         label  \n",
       "844098   0      \n",
       "1268963  0      \n",
       "1118710  1      \n",
       "340147   1      \n",
       "393637   0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Load Full Labeled Data ---\n",
    "# Note: load_dataset keeps labels for both train and test here\n",
    "df_train_full, df_test_full = utils.load_dataset(csv_path=\"data/sentiment_analysis.csv\")\n",
    "\n",
    "# --- Clean Text ---\n",
    "def clean_text(text):\n",
    "    text = str(text).lower() # Ensure input is string\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'@[^\\s]+', '', text)\n",
    "    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "print(\"Cleaning full dataset text...\")\n",
    "df_train_full['text'] = df_train_full['text'].apply(clean_text)\n",
    "df_test_full['text'] = df_test_full['text'].apply(clean_text)\n",
    "\n",
    "# --- Create a Small Subset ---\n",
    "subset_size_train = 10000 # Use 10k examples\n",
    "subset_size_test = 2000   # Use 2k examples\n",
    "\n",
    "if len(df_train_full) > subset_size_train:\n",
    "    df_train = df_train_full.sample(n=subset_size_train, random_state=SEED)\n",
    "else:\n",
    "    df_train = df_train_full\n",
    "\n",
    "if len(df_test_full) > subset_size_test:\n",
    "    df_test = df_test_full.sample(n=subset_size_test, random_state=SEED)\n",
    "else:\n",
    "    df_test = df_test_full\n",
    "\n",
    "print(f\"\\nUsing a SUBSET for training/evaluation:\")\n",
    "print(f\"  Training examples: {len(df_train)}\")\n",
    "print(f\"  Test examples: {len(df_test)}\")\n",
    "\n",
    "# Extract labels for the SUBSETS\n",
    "Y_train = df_train[\"label\"].values\n",
    "Y_test = df_test[\"label\"].values\n",
    "\n",
    "# Define labels\n",
    "ABSTAIN = -1; NEGATIVE = 0; POSITIVE = 1;\n",
    "\n",
    "print(\"\\nTraining Subset Head:\")\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing Slicing Functions (SFs)\n",
    "\n",
    "Slicing Functions (SFs) are similar to LFs but output a boolean mask indicating whether a data point belongs to the slice. We'll define a few SFs relevant to sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 3 Slicing Functions: ['short_tweet', 'has_negation', 'high_positive_polarity']\n",
      "\n",
      "Examples from the 'has_negation' slice (from test subset):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 58474.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57814</th>\n",
       "      <td>went to a harley davidson dealer to show some of my art this weekend allot of looks but no sales  ill be judging a tattoo comp next</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77033</th>\n",
       "      <td>itâs start raining now hmm second cloudy day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171509</th>\n",
       "      <td>just saw quotwallk to rememberquot again and its never get old</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136333</th>\n",
       "      <td>i was  when i found out you were in the same house im a huge fan toolol through my tv show im getting racing known in main stream</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173418</th>\n",
       "      <td>ahh thank god he has leftan angry gay man with a hang over is not my idea of fun on a saturday morninghi 2 all in twitt land</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       text  \\\n",
       "57814   went to a harley davidson dealer to show some of my art this weekend allot of looks but no sales  ill be judging a tattoo comp next   \n",
       "77033   itâs start raining now hmm second cloudy day                                                                                          \n",
       "171509  just saw quotwallk to rememberquot again and its never get old                                                                        \n",
       "136333  i was  when i found out you were in the same house im a huge fan toolol through my tv show im getting racing known in main stream     \n",
       "173418  ahh thank god he has leftan angry gay man with a hang over is not my idea of fun on a saturday morninghi 2 all in twitt land          \n",
       "\n",
       "        label  \n",
       "57814   0      \n",
       "77033   0      \n",
       "171509  1      \n",
       "136333  0      \n",
       "173418  1      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snorkel.slicing import slicing_function\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "\n",
    "# SF for short tweets\n",
    "@slicing_function()\n",
    "def short_tweet(x):\n",
    "    \"\"\"Tweets with fewer than 5 words.\"\"\"\n",
    "    return len(x.text.split()) < 5\n",
    "\n",
    "# SF for tweets containing negation words\n",
    "negation_words = [\"not\", \"no\", \"never\", \"ain't\", \"don't\", \"isn't\", \"can't\", \"won't\"]\n",
    "@slicing_function()\n",
    "def has_negation(x):\n",
    "    \"\"\"Tweets containing common negation words.\"\"\"\n",
    "    return any(word in x.text for word in negation_words)\n",
    "\n",
    "# SF using a preprocessor for high polarity\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_polarity_score(x):\n",
    "    scores = TextBlob(x.text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    return x\n",
    "\n",
    "@slicing_function(pre=[textblob_polarity_score])\n",
    "def high_positive_polarity(x):\n",
    "    \"\"\"Tweets with TextBlob polarity > 0.8\"\"\"\n",
    "    return x.polarity > 0.8\n",
    "\n",
    "# List of SFs to use\n",
    "# Removed 'is_question' due to previous zero coverage issue\n",
    "sfs = [\n",
    "    short_tweet,\n",
    "    has_negation,\n",
    "    high_positive_polarity\n",
    "]\n",
    "print(f\"Defined {len(sfs)} Slicing Functions: {[sf.name for sf in sfs]}\")\n",
    "\n",
    "# (Optional) Visualize examples from a slice\n",
    "from snorkel.slicing import slice_dataframe\n",
    "print(\"\\nExamples from the 'has_negation' slice (from test subset):\")\n",
    "# Apply the SF to the test subset DataFrame to get examples\n",
    "negation_df_subset = slice_dataframe(df_test, has_negation)\n",
    "display(negation_df_subset[['text', 'label']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Slices\n",
    "\n",
    "We can use slice_dataframe to see examples from a specific slice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Baseline Model and Monitor Slices\n",
    "Now, let's train a baseline model and see how it performs overall and on our defined slices. This process works with any model framework.\n",
    "\n",
    "\n",
    "Train a Baseline Classifier\n",
    "\n",
    "- We'll use scikit-learn's LogisticRegression with TF-IDF features as our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizing subset data with TF-IDF...\n",
      "Featurization complete.\n",
      "Training baseline Logistic Regression model on subset...\n",
      "Baseline model trained.\n",
      "\n",
      "Baseline Model Overall Test Subset Accuracy: 71.0%\n",
      "\n",
      "Applying Slicing Functions to test subset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 6307.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFs applied to test subset.\n",
      "\n",
      "Checking slice coverage on the test subset (S_test):\n",
      "- Slice 'short_tweet': 252 examples\n",
      "- Slice 'has_negation': 492 examples\n",
      "- Slice 'high_positive_polarity': 33 examples\n",
      "\n",
      "All slices appear to have coverage on the test subset.\n",
      "\n",
      "Scoring baseline model performance on test subset slices:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_tweet</th>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_negation</th>\n",
       "      <td>0.693089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_positive_polarity</th>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accuracy\n",
       "overall                 0.710000\n",
       "short_tweet             0.777778\n",
       "has_negation            0.693089\n",
       "high_positive_polarity  0.818182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from snorkel.slicing import PandasSFApplier\n",
    "from snorkel.analysis import Scorer\n",
    "\n",
    "# Featurize SUBSET data using TF-IDF\n",
    "print(\"Featurizing subset data with TF-IDF...\")\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_sparse, _ = utils.df_to_features(vectorizer, df_train, \"train\") # Fit on train subset\n",
    "X_test_sparse, _ = utils.df_to_features(vectorizer, df_test, \"test\")   # Transform test subset\n",
    "print(\"Featurization complete.\")\n",
    "\n",
    "# Train baseline model on the SUBSET\n",
    "print(\"Training baseline Logistic Regression model on subset...\")\n",
    "baseline_model = LogisticRegression(solver=\"liblinear\", C=0.1, random_state=SEED)\n",
    "baseline_model.fit(X=X_train_sparse, y=Y_train) # Train on subset labels\n",
    "print(\"Baseline model trained.\")\n",
    "\n",
    "# Get predictions and probabilities for the TEST SUBSET\n",
    "preds_test = baseline_model.predict(X_test_sparse)\n",
    "probs_test = baseline_model.predict_proba(X_test_sparse)\n",
    "\n",
    "# Calculate overall accuracy on the TEST SUBSET\n",
    "accuracy_baseline = baseline_model.score(X_test_sparse, Y_test) # Score on test subset\n",
    "print(f\"\\nBaseline Model Overall Test Subset Accuracy: {accuracy_baseline * 100:.1f}%\")\n",
    "\n",
    "# Apply SFs to TEST SUBSET\n",
    "print(\"\\nApplying Slicing Functions to test subset...\")\n",
    "applier = PandasSFApplier(sfs)\n",
    "S_test = applier.apply(df_test) # Apply to df_test (the test subset)\n",
    "print(\"SFs applied to test subset.\")\n",
    "\n",
    "# Check for empty slices on TEST SUBSET\n",
    "print(\"\\nChecking slice coverage on the test subset (S_test):\")\n",
    "empty_slices = []\n",
    "if hasattr(S_test, 'dtype') and S_test.dtype.names:\n",
    "    slice_names_in_S_test = S_test.dtype.names\n",
    "    for slice_name in slice_names_in_S_test:\n",
    "        coverage = S_test[slice_name].sum()\n",
    "        print(f\"- Slice '{slice_name}': {coverage} examples\")\n",
    "        if coverage == 0: empty_slices.append(slice_name)\n",
    "else: print(\"Warning: S_test format issue.\")\n",
    "\n",
    "if empty_slices: print(f\"\\nWarning: Empty slices found: {empty_slices}.\")\n",
    "else: print(\"\\nAll slices appear to have coverage on the test subset.\")\n",
    "\n",
    "# Score baseline model on TEST SUBSET slices\n",
    "# Using accuracy metric consistent with previous tutorials\n",
    "scorer = Scorer(metrics=[\"accuracy\"])\n",
    "print(\"\\nScoring baseline model performance on test subset slices:\")\n",
    "if not empty_slices:\n",
    "    try:\n",
    "        slice_scores = scorer.score_slices(\n",
    "            S=S_test, golds=Y_test, preds=preds_test, probs=probs_test, as_dataframe=True\n",
    "        )\n",
    "        display(slice_scores)\n",
    "    except ValueError as e: print(f\"\\nError during scoring: {e}\")\n",
    "    except Exception as e: print(f\"\\nUnexpected error during scoring: {e}\")\n",
    "else:\n",
    "    print(\"Skipping scoring due to empty slices.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Improve Slice Performance with SliceAwareClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we identified slices where our baseline model performed poorly compared to its overall accuracy. Now, we'll use Slice-based Learning, a technique that adds slice-specific components to our model to improve performance on those challenging subsets. Snorkel implements this via the SliceAwareClassifier.\n",
    "\n",
    "Constructing the SliceAwareClassifier\n",
    "\n",
    "First, we need a base PyTorch model architecture. We'll use the simple Multi-Layer Perceptron (MLP) defined in your utils.py file. Then, we initialize the SliceAwareClassifier.\n",
    "\n",
    "base_architecture: The core PyTorch model (our MLP).\n",
    "\n",
    "head_dim: The output dimension of the base_architecture before its final classification layer. This is used by the slice-specific heads.\n",
    "\n",
    "slice_names: The names of the slices we want the model to be aware of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Slice-Aware DataLoaders\n",
    "\n",
    "We need to apply our Slicing Functions (SFs) to the training data (df_train) to get S_train. Then, we create special PyTorch DataLoader objects that include this slice information alongside the features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing SliceAwareClassifier...\n",
      "SliceAwareClassifier initialized with DENSE base MLP.\n",
      "\n",
      "Applying Slicing Functions to train subset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 6730.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFs applied to train subset.\n",
      "Converting subset features to PyTorch DENSE tensors...\n",
      "PyTorch DENSE datasets created from subset.\n",
      "Creating slice-aware dataloaders for DENSE data...\n",
      "Dataloaders ready for DENSE data.\n"
     ]
    }
   ],
   "source": [
    "from snorkel.slicing import SliceAwareClassifier\n",
    "from snorkel.classification.data import DictDataset, DictDataLoader\n",
    "from snorkel.classification import Trainer\n",
    "\n",
    "# --- Initialize SliceAwareClassifier (using DENSE base MLP) ---\n",
    "print(\"\\nInitializing SliceAwareClassifier...\")\n",
    "slice_model = None # Initialize to None\n",
    "train_dl_slice = None\n",
    "test_dl_slice = None\n",
    "\n",
    "# Check required variables are defined and valid\n",
    "required_vars_init = ['X_train_sparse', 'sfs', 'scorer']\n",
    "missing_vars_init = [var for var in required_vars_init if var not in locals()]\n",
    "\n",
    "if missing_vars_init: print(f\"Error: Missing variables for initialization: {missing_vars_init}\")\n",
    "elif not isinstance(X_train_sparse, scipy.sparse.spmatrix): print(\"Error: X_train_sparse is not sparse.\")\n",
    "else:\n",
    "    bow_dim = X_train_sparse.shape[1]\n",
    "    hidden_dim = 128\n",
    "    try:\n",
    "        # Use the DENSE base MLP from utils.py\n",
    "        base_mlp = utils.get_pytorch_mlp_base(input_dim=bow_dim, hidden_dim=hidden_dim, num_layers=1)\n",
    "        head_dim_to_use = hidden_dim\n",
    "        slice_model = SliceAwareClassifier(\n",
    "            base_architecture=base_mlp, head_dim=head_dim_to_use,\n",
    "            slice_names=[sf.name for sf in sfs], scorer=scorer,\n",
    "        )\n",
    "        print(\"SliceAwareClassifier initialized with DENSE base MLP.\")\n",
    "    except AttributeError: print(\"Error: 'get_pytorch_mlp_base' not found in utils.py.\")\n",
    "    except Exception as e: print(f\"Error initializing SliceAwareClassifier: {e}\")\n",
    "\n",
    "# --- Prepare DENSE Slice-Aware DataLoaders (using SUBSET) ---\n",
    "if slice_model is not None:\n",
    "    print(\"\\nApplying Slicing Functions to train subset...\")\n",
    "    S_train = applier.apply(df_train) # Apply SFs to df_train (train subset)\n",
    "    print(\"SFs applied to train subset.\")\n",
    "\n",
    "    print(\"Converting subset features to PyTorch DENSE tensors...\")\n",
    "    try:\n",
    "        X_train_tensor = torch.FloatTensor(X_train_sparse.toarray()) # Dense Train Subset\n",
    "        X_test_tensor = torch.FloatTensor(X_test_sparse.toarray())   # Dense Test Subset\n",
    "        Y_train_tensor = torch.LongTensor(Y_train) # Train subset labels\n",
    "        Y_test_tensor = torch.LongTensor(Y_test)   # Test subset labels\n",
    "\n",
    "        train_dataset = DictDataset.from_tensors(X_train_tensor, Y_train_tensor, \"train\")\n",
    "        test_dataset = DictDataset.from_tensors(X_test_tensor, Y_test_tensor, \"test\")\n",
    "        print(\"PyTorch DENSE datasets created from subset.\")\n",
    "\n",
    "        BATCH_SIZE = 64\n",
    "        print(\"Creating slice-aware dataloaders for DENSE data...\")\n",
    "        # Create dataloaders using subset slice matrices\n",
    "        train_dl_slice = slice_model.make_slice_dataloader(train_dataset, S_train, shuffle=True, batch_size=BATCH_SIZE)\n",
    "        test_dl_slice = slice_model.make_slice_dataloader(test_dataset, S_test, shuffle=False, batch_size=BATCH_SIZE)\n",
    "        print(\"Dataloaders ready for DENSE data.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error preparing dense data/dataloaders: {e}.\")\n",
    "        train_dl_slice = None; test_dl_slice = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Slice-Aware Model\n",
    "\n",
    "Now we train the SliceAwareClassifier using Snorkel's Trainer. The trainer handles the multi-task learning process automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SliceAwareClassifier on subset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:: 100%|██████████| 157/157 [00:06<00:00, 24.84it/s, model/all/train/loss=0.478, model/all/train/lr=0.001]\n",
      "Epoch 1:: 100%|██████████| 157/157 [00:06<00:00, 25.30it/s, model/all/train/loss=0.229, model/all/train/lr=0.001]\n",
      "Epoch 2:: 100%|██████████| 157/157 [00:06<00:00, 24.29it/s, model/all/train/loss=0.117, model/all/train/lr=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SliceAwareClassifier training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Train Slice-Aware Model ---\n",
    "if slice_model is not None and train_dl_slice is not None:\n",
    "    print(\"\\nTraining SliceAwareClassifier on subset...\")\n",
    "    trainer = Trainer(n_epochs=3, lr=1e-3, progress_bar=True) #\n",
    "    try:\n",
    "        trainer.fit(slice_model, [train_dl_slice]) #\n",
    "        print(\"SliceAwareClassifier training complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred during training: {e}\")\n",
    "        slice_model = None # Mark model as failed\n",
    "else:\n",
    "    print(\"\\nSkipping SliceAwareClassifier training due to initialization errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Slice-Aware Model\n",
    "\n",
    "Finally, evaluate the trained SliceAwareClassifier on the test set slices. The score_slices method will report metrics for the main task and for each slice-specific head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating SliceAwareClassifier on test subset slices:\n",
      "\n",
      "Comparison with Baseline Model (on Test Subset):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>slice_aware_accuracy</th>\n",
       "      <th>improvement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.711000</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_tweet</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>-0.031746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_negation</th>\n",
       "      <td>0.693089</td>\n",
       "      <td>0.701220</td>\n",
       "      <td>0.008130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_positive_polarity</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        baseline_accuracy  slice_aware_accuracy  improvement\n",
       "slice_name                                                                  \n",
       "overall                 0.710000           0.711000              0.001000   \n",
       "short_tweet             0.777778           0.746032             -0.031746   \n",
       "has_negation            0.693089           0.701220              0.008130   \n",
       "high_positive_polarity  0.818182           0.909091              0.090909   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Evaluate Slice-Aware Model ---\n",
    "if slice_model is not None and test_dl_slice is not None:\n",
    "    print(\"\\nEvaluating SliceAwareClassifier on test subset slices:\")\n",
    "    try:\n",
    "        slice_aware_scores = slice_model.score_slices([test_dl_slice], as_dataframe=True) #\n",
    "\n",
    "        if 'slice_scores' in locals() and isinstance(slice_scores, pd.DataFrame):\n",
    "            print(\"\\nComparison with Baseline Model (on Test Subset):\")\n",
    "            comparison_df = slice_scores.rename(columns={\"accuracy\": \"baseline_accuracy\"})\n",
    "            score_col_name = 'score'\n",
    "            if score_col_name in slice_aware_scores.columns:\n",
    "                 slice_aware_scores['slice_name'] = slice_aware_scores['label'].apply(lambda x: x.replace('task_slice:', '').replace('_pred', '') if 'task_slice:' in x else ('overall' if x == 'task' else x))\n",
    "                 if comparison_df.index.name != 'slice_name': comparison_df.index.name = 'slice_name'\n",
    "                 comparison_df = comparison_df.reset_index().merge(slice_aware_scores[['slice_name', score_col_name]], on='slice_name', how='left')\n",
    "                 comparison_df = comparison_df.rename(columns={score_col_name: \"slice_aware_accuracy\"}).set_index('slice_name')\n",
    "                 if 'baseline_accuracy' in comparison_df.columns and 'slice_aware_accuracy' in comparison_df.columns:\n",
    "                     # Add a column for improvement\n",
    "                     comparison_df['improvement'] = comparison_df['slice_aware_accuracy'] - comparison_df['baseline_accuracy']\n",
    "                     display(comparison_df[['baseline_accuracy', 'slice_aware_accuracy', 'improvement']])\n",
    "                 else: print(\"Warning: Comparison table columns missing.\"); display(slice_aware_scores)\n",
    "            else: print(f\"Warning: Score column '{score_col_name}' missing.\"); display(slice_aware_scores)\n",
    "        else:\n",
    "            print(\"\\nBaseline scores not found/valid. Displaying SliceAwareClassifier scores only:\")\n",
    "            display(slice_aware_scores)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during SliceAwareClassifier evaluation: {e}\")\n",
    "else:\n",
    "    print(\"\\nSkipping SliceAwareClassifier evaluation due to initialization or training errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
